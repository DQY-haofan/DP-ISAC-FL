# ============================================================
# è„šæœ¬å: generate_viz_data.py
# ä½œç”¨: é‡‡é›†ç”¨äºé«˜çº§å¯è§†åŒ–(t-SNE, Heatmap)çš„é«˜ç»´æ•°æ®
# ç‰ˆæœ¬: Fixed (Solved KeyError: 'stga_alpha')
# ============================================================
import torch
import numpy as np
import os
import copy
import yaml
import torch.nn.functional as F
from runner import SimulationRunner
from server import Server
from stga import STGAAggregator
from datasets import partition_dataset_dirichlet, get_dataset


# 1. å®šä¹‰ä¸€ä¸ªâ€œé—´è°â€èšåˆå™¨ï¼Œç”¨æ¥æŠŠå†…éƒ¨æƒé‡å·å‡ºæ¥
class InstrumentedSTGA(STGAAggregator):
    def __init__(self, config):
        super().__init__(config)
        self.captured_weights = None
        self.captured_updates = None  # Flattened

    def aggregate(self, updates, client_types=None):
        # å¤ç”¨çˆ¶ç±»çš„é¢„å¤„ç†é€»è¾‘
        if not updates: return None

        # é‡æ–°å®ç°æ ¸å¿ƒæ‰“åˆ†é€»è¾‘ä»¥æ•è·æ•°æ® (ä¿æŒä¸åŸç‰ˆ stga.py å®Œå…¨ä¸€è‡´)
        flat_updates = [self._flatten(u) for u in updates]
        update_matrix = torch.stack(flat_updates).to(self.device)

        # ä¿å­˜ç”¨äº t-SNE çš„åŸå§‹å‘é‡ (åªå­˜ CPU ç‰ˆä»¥çœæ˜¾å­˜)
        self.captured_updates = update_matrix.detach().cpu().numpy()

        # --- STGA é€»è¾‘å¤ç° (ä¸ºäº†è·å– weights) ---
        # 1. Norm Clipping
        update_norms = torch.norm(update_matrix, p=2, dim=1)
        median_norm = torch.median(update_norms)
        threshold = median_norm * 1.5
        clip_factor = torch.clamp(threshold / (update_norms + 1e-6), max=1.0)
        update_matrix_clipped = update_matrix * clip_factor.unsqueeze(1)

        # 2. Spatial
        spatial_center = torch.median(update_matrix_clipped, dim=0).values
        s_spat_cos = F.cosine_similarity(update_matrix_clipped, spatial_center.unsqueeze(0), dim=1)
        dists = torch.norm(update_matrix_clipped - spatial_center, p=2, dim=1)
        sigma = torch.median(dists) + 1e-6
        s_spat_dist = torch.exp(-dists / sigma)
        s_spat = (s_spat_cos + 1) / 2 * 0.5 + s_spat_dist * 0.5

        # 3. Temporal
        if len(self.history_updates) > 0:
            expected_update = self.history_updates[-1].to(self.device)
            s_temp = F.cosine_similarity(update_matrix_clipped, expected_update.unsqueeze(0), dim=1)
        else:
            s_temp = torch.ones(len(updates)).to(self.device)
        s_temp_norm = (s_temp + 1) / 2

        # 4. Weights
        # [Fix] ç¡®ä¿ self.alpha å­˜åœ¨ (çˆ¶ç±»å·²åˆå§‹åŒ–)
        trust_scores = self.alpha * s_temp_norm + (1 - self.alpha) * s_spat
        weights = F.softmax(trust_scores * 2.0, dim=0)

        # æ•è·æƒé‡ï¼
        self.captured_weights = weights.detach().cpu().numpy()

        # è°ƒç”¨çˆ¶ç±»å®Œæˆå®é™…èšåˆ (ç¡®ä¿è®­ç»ƒä¸å—å½±å“)
        return super().aggregate(updates, client_types)


# 2. è¿è¡Œé‡‡é›†æµç¨‹
def run_harvest():
    print("ğŸšœ Starting Visualization Data Harvest (20 Rounds)...")
    os.makedirs('viz_data', exist_ok=True)

    # è¯»å–é…ç½®
    with open('config.yaml') as f:
        conf = yaml.safe_load(f)

    # [Critical Fix] ä¸è¦è¦†ç›–æ•´ä¸ª r_jora å­—å…¸ï¼Œè€Œæ˜¯æ›´æ–°å®ƒ
    # è¿™æ ·å¯ä»¥ä¿ç•™ config.yaml é‡Œçš„ stga_alpha
    if 'r_jora' not in conf: conf['r_jora'] = {}
    conf['r_jora'].update({
        'enabled': True,
        'enable_stga': True,
        'enable_optimal_dp': True,
        'enable_secure_isac': True
    })

    # å…œåº•ï¼šä¸‡ä¸€ config.yaml é‡ŒçœŸçš„æ²¡æœ‰ï¼Œèµ‹é»˜è®¤å€¼
    if 'stga_alpha' not in conf['r_jora']:
        conf['r_jora']['stga_alpha'] = 0.5

    conf['num_rounds'] = 20  # åªè·‘20è½®
    conf['scenario'] = 'Viz_Harvest'
    conf['aggregator'] = 'STGA'

    # ä½¿ç”¨è¾ƒå¼ºçš„æ”»å‡»æ¥å‡¸æ˜¾é˜²å¾¡æ•ˆæœ
    conf['attack'] = {'malicious_fraction': 0.2, 'lambda_attack': 3.0, 'tau_sim': 0.5, 't_vgae': 1, 'q_eaves': 0.8,
                      'eaves_sigma': 0.005, 'vgae_epochs': 5, 'vgae_lr': 0.01, 'latent_dim': 16}

    if torch.cuda.is_available(): conf['device'] = 'cuda'

    # åˆå§‹åŒ–ç¯å¢ƒ
    ds, _ = get_dataset(conf['dataset'], conf['data_root'])
    idx = partition_dataset_dirichlet(ds, conf['num_clients'], conf['alpha'], seed=42)

    server = Server(conf, ds, idx)

    # [æ³¨å…¥] æ›¿æ¢èšåˆå™¨ä¸ºé—´è°èšåˆå™¨
    # æ³¨æ„ï¼šå¿…é¡»é‡æ–°ä¼ å…¥å®Œæ•´çš„ conf
    server.aggregator = InstrumentedSTGA(conf)

    # è®°å½•å®¢æˆ·ç«¯ç±»å‹
    client_types = np.array(
        ['Malicious' if i in server.malicious_ids else 'Benign' for i in range(conf['num_clients'])])
    np.save('viz_data/client_types.npy', client_types)

    # å¾ªç¯
    for t in range(conf['num_rounds']):
        print(f"   Harvesting Round {t}...")
        server.run_round(t)

        # A. ä¿å­˜æƒé‡ (Heatmap)
        if server.aggregator.captured_weights is not None:
            np.save(f'viz_data/weights_r{t}.npy', server.aggregator.captured_weights)

        # B. ä¿å­˜æ›´æ–°å‘é‡ (t-SNE) - ä»…ä¿å­˜å…³é”®è½®æ¬¡
        if t in [0, 5, 10, 19]:
            np.save(f'viz_data/updates_r{t}.npy', server.aggregator.captured_updates)

        # C. ä¿å­˜ ISAC æ©ç 
        if hasattr(server.isac_scheduler, 'last_mask') and server.isac_scheduler.last_mask is not None:
            np.save(f'viz_data/mask_r{t}.npy', server.isac_scheduler.last_mask.cpu().numpy())

    print("âœ… Data Harvest Complete. Check 'viz_data/' folder.")


if __name__ == "__main__":
    run_harvest()