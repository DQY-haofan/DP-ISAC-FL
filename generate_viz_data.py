# ============================================================
# è„šæœ¬å: generate_viz_data_final.py (v3.0 Ultimate)
# ä½œç”¨: ä¸€ç«™å¼é‡‡é›†æ‰€æœ‰å¯è§†åŒ–æ‰€éœ€çš„é«˜ç»´æ•°æ®
# æ–°å¢: L2èŒƒæ•° (Norms) + ä½™å¼¦ç›¸ä¼¼åº¦ (Cosines) -> å®Œç¾è§£é‡Šæ”»é˜²æœºç†
# ============================================================
import torch
import numpy as np
import os
import yaml
import torch.nn.functional as F
from runner import SimulationRunner
from server import Server
from stga import STGAAggregator
from datasets import partition_dataset_dirichlet, get_dataset


# --- å®šä¹‰é—´è°èšåˆå™¨ ---
class InstrumentedSTGA(STGAAggregator):
    def __init__(self, config):
        super().__init__(config)
        # æ•°æ®ç¼“å­˜åŒº
        self.captured_weights = None
        self.captured_updates = None
        self.captured_norms = None  # [New] è§£é‡Šä¸ºä»€ä¹ˆèƒ½é˜²ä½ (å¹…åº¦å¼‚å¸¸)
        self.captured_cosines = None  # [New] è§£é‡Šä¸ºä»€ä¹ˆ Krum é˜²ä¸ä½ (æ–¹å‘ä¼ªè£…)

    def aggregate(self, updates, client_types=None):
        if not updates: return None

        # 1. é¢„å¤„ç†
        flat_updates = [self._flatten(u) for u in updates]
        update_matrix = torch.stack(flat_updates).to(self.device)

        # [Capture 1] åŸå§‹æ›´æ–°å‘é‡ (ç”¨äº t-SNE)
        self.captured_updates = update_matrix.detach().cpu().numpy()

        # [Capture 2] L2 èŒƒæ•° (ç”¨äº Boxplot)
        norms = torch.norm(update_matrix, p=2, dim=1)
        self.captured_norms = norms.detach().cpu().numpy()

        # --- å¤ç° STGA é€»è¾‘ä»¥æ•è·ä¸­é—´å˜é‡ ---

        # è®¡ç®—ç©ºé—´ä¸­å¿ƒ (ç”¨äºè®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦)
        # æ³¨æ„ï¼šä¸ºäº†å…¬å¹³å¯¹æ¯”ï¼Œæˆ‘ä»¬è®¡ç®—ç›¸å¯¹äºâ€œæœªè£å‰ªâ€ä¸­å¿ƒçš„ç›¸ä¼¼åº¦ï¼Œçœ‹æ”»å‡»è€…ä¼ªè£…å¾—æœ‰å¤šåƒ
        raw_center = torch.median(update_matrix, dim=0).values
        cos_sim = F.cosine_similarity(update_matrix, raw_center.unsqueeze(0), dim=1)

        # [Capture 3] ä½™å¼¦ç›¸ä¼¼åº¦ (ç”¨äºè¯æ˜æ”»å‡»è€…çš„æ–¹å‘ä¼ªè£…)
        self.captured_cosines = cos_sim.detach().cpu().numpy()

        # === æ­£å¸¸çš„ STGA å¤„ç†æµç¨‹ ===
        # Norm Clipping
        median_norm = torch.median(norms)
        threshold = median_norm * 1.5
        clip_factor = torch.clamp(threshold / (norms + 1e-6), max=1.0)
        update_matrix_clipped = update_matrix * clip_factor.unsqueeze(1)

        # Spatial Score
        spatial_center = torch.median(update_matrix_clipped, dim=0).values
        s_spat_cos = F.cosine_similarity(update_matrix_clipped, spatial_center.unsqueeze(0), dim=1)
        dists = torch.norm(update_matrix_clipped - spatial_center, p=2, dim=1)
        sigma = torch.median(dists) + 1e-6
        s_spat_dist = torch.exp(-dists / sigma)
        s_spat = (s_spat_cos + 1) / 2 * 0.5 + s_spat_dist * 0.5

        # Temporal Score
        if len(self.history_updates) > 0:
            expected_update = self.history_updates[-1].to(self.device)
            s_temp = F.cosine_similarity(update_matrix_clipped, expected_update.unsqueeze(0), dim=1)
        else:
            s_temp = torch.ones(len(updates)).to(self.device)
        s_temp_norm = (s_temp + 1) / 2

        # Final Weights
        trust_scores = self.alpha * s_temp_norm + (1 - self.alpha) * s_spat
        weights = F.softmax(trust_scores * 2.0, dim=0)

        # [Capture 4] æœ€ç»ˆæƒé‡ (ç”¨äº Heatmap)
        self.captured_weights = weights.detach().cpu().numpy()

        # è°ƒç”¨çˆ¶ç±»å®Œæˆå®é™…èšåˆ
        return super().aggregate(updates, client_types)


# --- ä¸»ç¨‹åº ---
def run_harvest():
    print("ğŸšœ Starting Final Visualization Data Harvest (25 Rounds)...")
    # æ¸…ç†æ—§æ•°æ®
    import shutil
    if os.path.exists('viz_data'): shutil.rmtree('viz_data')
    os.makedirs('viz_data', exist_ok=True)

    # 1. åŠ è½½å¹¶ä¿®è¡¥é…ç½®
    with open('config.yaml') as f:
        conf = yaml.safe_load(f)

    # å¼ºåˆ¶å¼€å¯ R-JORA
    if 'r_jora' not in conf: conf['r_jora'] = {}
    conf['r_jora'].update({
        'enabled': True, 'enable_stga': True, 'enable_optimal_dp': True, 'enable_secure_isac': True
    })
    # ç¡®ä¿å¿…è¦å‚æ•°å­˜åœ¨
    if 'stga_alpha' not in conf['r_jora']: conf['r_jora']['stga_alpha'] = 0.5

    # è®¾ç½®é‡‡é›†å‚æ•°
    conf['num_rounds'] = 25  # è·‘25è½®è¶³å¤Ÿå±•ç¤ºæ”¶æ•›åˆæœŸçš„åŠ¨æ€
    conf['scenario'] = 'Viz_Harvest'
    conf['aggregator'] = 'STGA'

    # [å…³é”®] ä½¿ç”¨èƒ½äº§ç”Ÿæ˜¾è‘—å¯¹æ¯”çš„æ”»å‡»å‚æ•° (Exp 1/2 éªŒè¯è¿‡çš„å‚æ•°)
    # Lambda=5.0 èƒ½äº§ç”Ÿå·¨å¤§çš„ Norm å·®å¼‚ï¼Œéå¸¸é€‚åˆç”»å›¾
    conf['attack'] = {
        'malicious_fraction': 0.2,
        'lambda_attack': 5.0,
        'tau_sim': 0.5,
        't_vgae': 1,
        'q_eaves': 0.8,
        'eaves_sigma': 0.005,
        'vgae_epochs': 5,
        'vgae_lr': 0.01,
        'latent_dim': 16
    }

    if torch.cuda.is_available(): conf['device'] = 'cuda'

    # 2. åˆå§‹åŒ–
    print("   Loading data...")
    ds, _ = get_dataset(conf['dataset'], conf['data_root'])
    # å›ºå®šç§å­ 42ï¼Œç¡®ä¿å’Œè®ºæ–‡é‡Œçš„ Exp 1/2 ä¸€è‡´
    idx = partition_dataset_dirichlet(ds, conf['num_clients'], conf['alpha'], seed=42)

    server = Server(conf, ds, idx)

    # æ³¨å…¥é—´è°èšåˆå™¨
    server.aggregator = InstrumentedSTGA(conf)

    # ä¿å­˜å®¢æˆ·ç«¯ç±»å‹æ ‡ç­¾ (0=Benign, 1=Malicious)
    client_types = np.array(
        ['Malicious' if i in server.malicious_ids else 'Benign' for i in range(conf['num_clients'])])
    np.save('viz_data/client_types.npy', client_types)
    print(f"   Setup complete. Malicious nodes: {len(server.malicious_ids)}")

    # 3. è¿è¡Œå¾ªç¯
    for t in range(conf['num_rounds']):
        print(f"   Harvesting Round {t + 1}/{conf['num_rounds']}...")
        server.run_round(t)

        # ä¿å­˜å„ç±»æ•°æ®
        if server.aggregator.captured_weights is not None:
            # æƒé‡
            np.save(f'viz_data/weights_r{t}.npy', server.aggregator.captured_weights)
            # èŒƒæ•° [æ–°å¢]
            np.save(f'viz_data/norms_r{t}.npy', server.aggregator.captured_norms)
            # ä½™å¼¦ç›¸ä¼¼åº¦ [æ–°å¢]
            np.save(f'viz_data/cosines_r{t}.npy', server.aggregator.captured_cosines)

        # æ¨¡å‹å‘é‡ (ä»…ä¿å­˜å…³é”®å¸§ï¼Œæ–‡ä»¶è¾ƒå¤§)
        if t in [0, 5, 10, 15, 20, 24]:
            np.save(f'viz_data/updates_r{t}.npy', server.aggregator.captured_updates)

        # ISAC æ©ç 
        if hasattr(server.isac_scheduler, 'last_mask') and server.isac_scheduler.last_mask is not None:
            np.save(f'viz_data/mask_r{t}.npy', server.isac_scheduler.last_mask.cpu().numpy())

    print("âœ… Data Harvest Complete. All high-dim data saved in 'viz_data/'.")


if __name__ == "__main__":
    run_harvest()