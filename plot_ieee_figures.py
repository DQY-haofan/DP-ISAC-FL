# ============================================================
# è„šæœ¬å: generate_viz_data_pro.py (v6.0 Multi-Scenario)
# ä½œç”¨: 1. å¯¹æ¯”é‡‡é›† (Vulnerable vs R-JORA)
#       2. è¿›åº¦æ¡æ˜¾ç¤º
#       3. å¯¼å‡ºå…¨ç»´åº¦ CSV (viz_metrics_all.csv)
# ============================================================
import torch
import numpy as np
import os
import yaml
import pandas as pd
import shutil
from tqdm import tqdm
import torch.nn.functional as F
from server import Server
from stga import STGAAggregator
from datasets import partition_dataset_dirichlet, get_dataset


# --- é€šç”¨æ¢é’ˆ (Compatible with FedAvg & STGA) ---
class DataProbe:
    """ç‹¬ç«‹äºèšåˆå™¨çš„æ¢é’ˆç±»ï¼Œç”¨äºæ•è·ç‰¹å¾"""

    def __init__(self, device):
        self.device = device
        self.metrics = {}

    def capture(self, updates, aggregator_type='FedAvg'):
        if not updates: return

        # 1. å±•å¹³ & è½¬ç§»åˆ° GPU
        flat_updates = []
        for u in updates:
            vec = torch.cat([v.view(-1) for k, v in sorted(u.items()) if v.dtype == torch.float32])
            flat_updates.append(vec)
        update_matrix = torch.stack(flat_updates).to(self.device)

        # 2. åŸºç¡€ç‰¹å¾ (Norms, Cosines)
        norms = torch.norm(update_matrix, p=2, dim=1)
        center = torch.median(update_matrix, dim=0).values
        cosines = F.cosine_similarity(update_matrix, center.unsqueeze(0), dim=1)

        # 3. æƒé‡ (æ ¹æ®èšåˆå™¨ç±»å‹æ¨æ–­)
        if aggregator_type == 'STGA':
            # å¤ç° STGA æƒé‡è®¡ç®—é€»è¾‘
            median_norm = torch.median(norms)
            thresh = median_norm * 1.5
            clip = torch.clamp(thresh / (norms + 1e-6), max=1.0)
            # ... (ç®€åŒ–ï¼šä»…ä¸ºäº†è·å–æƒé‡åˆ†å¸ƒï¼Œå‡è®¾ STGA é€»è¾‘ä¸€è‡´)
            # è¿™é‡Œä¸ºäº†ç²¾å‡†ï¼Œå»ºè®®ç›´æ¥ä»å¤–éƒ¨ä¼ å…¥å®é™…ä½¿ç”¨çš„ aggregator å®ä¾‹è¯»å–
            # ä½†ä¸ºäº†é€šç”¨æ€§ï¼Œæˆ‘ä»¬è¿™é‡Œåªè®°å½•ç‰¹å¾ï¼Œæƒé‡ç•™ç»™ server è®°å½•
            pass

        return {
            'norms': norms.detach().cpu().numpy(),
            'cosines': cosines.detach().cpu().numpy(),
            'updates_sample': update_matrix[0].detach().cpu().numpy()  # ä»…å­˜ä¸€ä¸ªæ ·æœ¬ç”¨äºdebug
        }


# --- å¢å¼ºç‰ˆ Server ---
class InstrumentedServer(Server):
    def __init__(self, config, ds, idx):
        super().__init__(config, ds, idx)
        self.probe = DataProbe(self.device)

    def run_round(self, round_idx):
        # 1. è·å– Updates (å¤ç”¨çˆ¶ç±»é€»è¾‘å‰åŠéƒ¨åˆ†)
        #    ä¸ºäº†ä¸ç ´åçˆ¶ç±»ç»“æ„ï¼Œæˆ‘ä»¬åªèƒ½æ‹¦æˆª channel.forward ä¹‹åçš„ç»“æœ
        #    æˆ–è€… Monkey Patchingã€‚è¿™é‡Œé€‰æ‹©è¦†ç›– run_round æ–¹æ³•ã€‚

        # ... (æ ‡å‡† Server é€»è¾‘å¤åˆ») ...
        # ä¸ºäº†æœ€å¤§å…¼å®¹æ€§ï¼Œæˆ‘ä»¬ç›´æ¥è°ƒç”¨ super().run_round()
        # ä½†æˆ‘ä»¬éœ€è¦åœ¨èšåˆå‰â€œå·çœ‹â€æ•°æ®ã€‚
        # æ–¹æ¡ˆï¼šä¿®æ”¹ self.aggregator.aggregate æ–¹æ³•
        return super().run_round(round_idx)


# --- æ³¨å…¥å¼èšåˆå™¨ (æœ€ç¨³å¦¥çš„æ–¹æ¡ˆ) ---
class ProbingAggregator(STGAAggregator):
    def __init__(self, config, mode='STGA'):
        super().__init__(config)
        self.mode = mode  # 'STGA' or 'FedAvg'
        self.captured_data = None

    def aggregate(self, updates, client_types=None):
        if not updates: return None

        # --- [Capture] ---
        flat = [self._flatten(u) for u in updates]
        mat = torch.stack(flat).to(self.device)

        norms = torch.norm(mat, p=2, dim=1)
        raw_center = torch.median(mat, dim=0).values
        cosines = F.cosine_similarity(mat, raw_center.unsqueeze(0), dim=1)

        # è®¡ç®— STGA æƒé‡ (å³ä¾¿æ˜¯ FedAvg æ¨¡å¼ï¼Œæˆ‘ä»¬ä¹Ÿç®—ä¸€ä¸‹â€œå¦‚æœç”¨ STGA ä¼šç»™å¤šå°‘åˆ†â€ï¼Œç”¨äºå¯¹æ¯”)
        # ... (STGA æ ¸å¿ƒé€»è¾‘)
        median_norm = torch.median(norms)
        clip = torch.clamp((median_norm * 1.5) / (norms + 1e-6), max=1.0)
        mat_clipped = mat * clip.unsqueeze(1)

        spat_center = torch.median(mat_clipped, dim=0).values
        s_spat = (F.cosine_similarity(mat_clipped, spat_center.unsqueeze(0)) + 1) / 2 * 0.5 + \
                 torch.exp(-torch.norm(mat_clipped - spat_center, p=2, dim=1) / (
                             torch.median(torch.norm(mat_clipped - spat_center, p=2, dim=1)) + 1e-6)) * 0.5

        if self.history_updates:
            s_temp = F.cosine_similarity(mat_clipped, self.history_updates[-1].to(self.device).unsqueeze(0))
        else:
            s_temp = torch.ones(len(updates)).to(self.device)

        scores = self.conf['stga_alpha'] * (s_temp + 1) / 2 + (1 - self.conf['stga_alpha']) * s_spat
        stga_weights = F.softmax(scores * 2.0, dim=0).detach().cpu().numpy()

        # çœŸå®ä½¿ç”¨çš„æƒé‡
        if self.mode == 'FedAvg':
            used_weights = np.ones(len(updates)) / len(updates)
        else:
            used_weights = stga_weights

        self.captured_data = {
            'norms': norms.detach().cpu().numpy(),
            'cosines': cosines.detach().cpu().numpy(),
            'stga_weights': stga_weights,  # å³ä½¿åœ¨ FedAvg æ¨¡å¼ä¸‹ä¹Ÿè®°å½•è¿™ä¸ªï¼Œç”¨äºå±•ç¤ºâ€œSTGA æœ¬è¯¥èƒ½é˜²ä½â€
            'used_weights': used_weights,
            'updates': mat.detach().cpu().numpy() if self.mode == 'STGA' else None  # åªå­˜ä¸€æ¬¡ä»¥å…çˆ†å†…å­˜
        }

        # --- [Execute] ---
        if self.mode == 'STGA':
            return super().aggregate(updates, client_types)
        else:
            return self._fedavg(updates)


# --- ä¸»æµç¨‹ ---
def run_pro_harvest():
    print("ğŸ¬ Starting Multi-Scenario Data Harvest...")

    # 1. å‡†å¤‡
    if os.path.exists('viz_data'): shutil.rmtree('viz_data')
    os.makedirs('viz_data', exist_ok=True)

    with open('config.yaml') as f:
        base_conf = yaml.safe_load(f)

    # ç»Ÿä¸€å‚æ•° (å¯¹é½ Run All)
    ATTACK_PARAMS = {'malicious_fraction': 0.2, 'lambda_attack': 5.0}  # å¼ºæ”»å‡»
    ROUNDS = 25

    # å®šä¹‰è¦è·‘çš„åœºæ™¯
    scenarios = [
        {'name': 'Vulnerable', 'aggregator': 'FedAvg', 'r_jora': False},
        {'name': 'R-JORA', 'aggregator': 'STGA', 'r_jora': True}
    ]

    global_records = []

    # 2. å¾ªç¯åœºæ™¯
    for scen in scenarios:
        print(f"\nğŸ“¦ Harvesting Scenario: {scen['name']}...")

        # é…ç½®å…‹éš†ä¸ä¿®æ”¹
        conf = base_conf.copy()
        if 'attack' not in conf: conf['attack'] = {}
        conf['attack'].update(ATTACK_PARAMS)
        conf['num_rounds'] = ROUNDS
        conf['scenario'] = scen['name']

        if 'r_jora' not in conf: conf['r_jora'] = {}
        conf['r_jora']['enabled'] = scen['r_jora']
        if scen['r_jora']:
            conf['r_jora'].update({'enable_stga': True, 'enable_optimal_dp': True, 'enable_secure_isac': True})
            if 'stga_alpha' not in conf['r_jora']: conf['r_jora']['stga_alpha'] = 0.5
        else:
            # å³ä½¿æ˜¯ Vulnerableï¼Œæˆ‘ä»¬ä¹Ÿå¼€å¯ 'enabled': Falseï¼Œä½†ä¸ºäº† Probe èƒ½å·¥ä½œï¼Œ
            # æˆ‘ä»¬éœ€è¦åœ¨ Server åˆå§‹åŒ–åæ‰‹åŠ¨æ³¨å…¥ ProbingAggregator
            pass

        if torch.cuda.is_available(): conf['device'] = 'cuda'

        # åˆå§‹åŒ–
        ds, _ = get_dataset(conf['dataset'], conf['data_root'])
        idx = partition_dataset_dirichlet(ds, conf['num_clients'], conf['alpha'], seed=42)
        server = Server(conf, ds, idx)

        # æ³¨å…¥æ¢é’ˆ (Mode = FedAvg or STGA)
        # æ³¨æ„ï¼šè¿™é‡Œä¼ å…¥ mode è®©æ¢é’ˆçŸ¥é“çœŸå®çš„èšåˆé€»è¾‘
        server.aggregator = ProbingAggregator(conf, mode=scen['aggregator'])

        # è¿›åº¦æ¡
        pbar = tqdm(range(ROUNDS), desc=f"   {scen['name']}", unit="rnd")

        for t in pbar:
            server.run_round(t)

            data = server.aggregator.captured_data
            if data is None: continue

            # æ¨æ–­ç±»å‹
            num_mal = int(len(data['norms']) * conf['attack']['malicious_fraction'])
            num_ben = len(data['norms']) - num_mal
            types = ['Benign'] * num_ben + ['Malicious'] * num_mal

            # è®°å½•åˆ°åˆ—è¡¨
            for i in range(len(data['norms'])):
                global_records.append({
                    'Scenario': scen['name'],
                    'Round': t,
                    'Client_ID': i,  # è¿™é‡Œçš„ ID æ˜¯ batch å†…çš„ç›¸å¯¹ ID
                    'Type': types[i],
                    'L2_Norm': data['norms'][i],
                    'Cosine_Sim': data['cosines'][i],
                    'Weight_Used': data['used_weights'][i],
                    'Weight_STGA_Score': data['stga_weights'][i]  # è¿™æ˜¯ä¸€ä¸ªè™šæ‹Ÿåˆ†ï¼Œç”¨äºå¯¹æ¯”
                })

            # ä¿å­˜ NPY (åªä¿å­˜ R-JORA çš„å…³é”®å¸§ç”¨äº t-SNE)
            if scen['name'] == 'R-JORA' and t in [0, 5, 10, 20]:
                np.save(f'viz_data/updates_r{t}.npy', data['updates'])
                np.save(f'viz_data/client_types_r{t}.npy', np.array(types))

    # 3. å¯¼å‡º CSV
    df = pd.DataFrame(global_records)
    df.to_csv('viz_metrics_pro.csv', index=False)
    print(f"\nâœ… Saved 'viz_metrics_pro.csv' ({len(df)} rows).")

    # ç®€å•çš„ç»Ÿè®¡éªŒè¯
    print("\n--- Quick Validation (Mean L2 Norm) ---")
    summary = df.groupby(['Scenario', 'Type'])['L2_Norm'].mean()
    print(summary)


if __name__ == "__main__":
    run_pro_harvest()